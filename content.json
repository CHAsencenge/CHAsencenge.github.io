{"meta":{"title":"解字","subtitle":null,"description":"解字无果","author":"CHAsencenge","url":"http://yoursite.com","root":"/"},"pages":[{"title":"tags","date":"2020-07-07T02:57:07.000Z","updated":"2020-07-07T02:58:34.536Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-07-07T02:56:17.000Z","updated":"2020-07-07T02:57:56.527Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Laya Basketball踩坑记录","slug":"Laya-Basketball踩坑记录","date":"2020-07-16T08:36:28.000Z","updated":"2020-07-16T15:52:42.668Z","comments":true,"path":"2020/07/16/Laya-Basketball踩坑记录/","link":"","permalink":"http://yoursite.com/2020/07/16/Laya-Basketball踩坑记录/","excerpt":"Laya3D小项目中的踩坑历程","text":"Laya3D小项目中的踩坑历程 测试Unity导出的Scene（仅包含3D球架）在导入Laya后的显示，发现若导出.lh文件，在Laya创建的Scene中挂载脚本运行时会报“cannot read ‘_addCamera’ of undefined”错误，解决此问题时选择重新导出.ls文件 相应脚本： 123456789101112131415161718import &#123; ui &#125; from \"./../ui/layaMaxUI\";export default class SmallScene extends Laya.Script &#123; constructor() &#123; super(); &#125; onEnable(): void &#123; Laya3D.init(0, 0); Laya.Stat.show(); Laya.stage.scaleMode = Laya.Stage.SCALE_FULL; Laya.stage.screenMode = Laya.Stage.SCREEN_NONE; Laya.Scene3D.load(\"res/Loading/LayaScene_SmallScene/Conventional/SmallScene.ls\", Laya.Handler.create(null, function(scene:Laya.Scene3D):void &#123; Laya.stage.addChild(scene) as Laya.Scene3D; &#125;)); &#125; onDisable(): void &#123; &#125;&#125;new SmallScene; 导出文件说明：ls — 场景文件： Json文件，包含场景中所有节点的数据信息，包含光照贴图信息lh — 层级文件： Json文件，包含场景中所有节点的数据信息，不包含光照贴图信息lt — 地形文件： Json文件，包含地形中的数据信息lm — 网格文件： 二进制文件，包含模型所有顶点的数据信息lmat — 材质文件： Json文件，包含光照，贴图，渲染模式等基本材质信息lsani — 蒙皮动画文件：二进制文件，包含骨骼动画帧率信息lrani — 刚体动画文件：二进制文件，包含刚体动画帧率信息lav — 新版动画节点文件：Json文件，只包含Animator组件下节点的数据信息lani — 新版动画文件：二进制文件，包含Animator动画帧率信息 Mesh Collider 和 Box Collider的选择：篮筐处有两个Trigger，一个在篮筐一个在篮网，篮筐环附近用Box Collider（元碰撞器），篮网用Mesh Collider（网格），后者渲染时消耗资源比前者大很多 如何进一步操作导入的Scene中的子对象？laya.display.Node 测试时在Laya.Scene3D.load的call中添加： 1console.log(\"scene.numChildren:\", scene.numChildren); 可在运行时查看scene中的子对象个数 其他类似操作代码如下： 123456789101112Laya.Scene3D.load(\"res/Loading/LayaScene_SmallScene/Conventional/SmallScene.ls\", Laya.Handler.create(null, function(scene:Laya.Scene3D):void &#123; //myScene = scene; Laya.stage.addChild(scene) as Laya.Scene3D; //var camera = new Laya.Camera(0, 3, 10); //scene.addChild(camera); console.log(\"scene.numChildren:\", scene.numChildren); let sprite:Laya.Sprite3D = new Laya.Sprite3D(); scene.addChildAt(sprite, 5); console.log(scene.getChildAt(3).name); console.log(scene.getChildAt(4).name); console.log(scene.getChildAt(5).name); &#125;)); 关于Laya.Handler.createHandler是事件处理器类 laya.utils.Handler create(caller:*, method:Fuction, args:Array = null, once:Boolean = true): Handler caller:* -执行域(this) method:Function -回调方法 args:Array -携带的参数 once:Boolean -是否只执行一次，默认为true 注意once后或者Handler.recover()后不要再使用此对象","categories":[{"name":"Laya","slug":"Laya","permalink":"http://yoursite.com/categories/Laya/"}],"tags":[{"name":"Laya","slug":"Laya","permalink":"http://yoursite.com/tags/Laya/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://yoursite.com/tags/TypeScript/"}]},{"title":"LoRa的三种class","slug":"LoRa的三种class","date":"2020-07-14T14:30:06.000Z","updated":"2020-07-14T15:04:56.290Z","comments":true,"path":"2020/07/14/LoRa的三种class/","link":"","permalink":"http://yoursite.com/2020/07/14/LoRa的三种class/","excerpt":"LoRa class A, class B, class C三种工作模式","text":"LoRa class A, class B, class C三种工作模式 class A接收窗口RX1一般是在上行后1秒开始，接收窗口RX2是在上行后2秒开始 终端有数据了，就上报，顺便收一下服务器下发的指令。终端没数据的时候，服务器下发不了指令 class B有一个同步时隙beacon，还有一个固定周期的接收窗口ping时隙。(隔几十秒收一个数据。其他时候都在休眠) 终端和基站约定一个时间下发数据，终端和基站依靠beacon信号校对时间，确保约定的时间不会错位 ClassB的目的是使得节点具有在预定时间打开接收窗口（称之为ping slot）的能力。一个支持ClassB的网络，所有的网关都必须同步发送beacon class C在class A的基础上，在class A休眠期间，一直打开接收窗口RX2（几乎随时可以接收数据） BeaconLoRa一旦约定好了时间，基站就默认设备一定会在那个时间点接收，所以需要严格的时间同步。Beacon则是时间同步的最关键的地方 节点由ClassA切换到ClassB之前必须收到beacon，进入ClassB之后还需要周期搜索/接收beacon，从而同步时钟。Class B节点可能临时收不到beacon，此时节点要逐渐加宽beacon和ping的接收窗。如果收到beacon后2小时收不到新的beacon，节点需使用内部时钟保持同步","categories":[{"name":"LoRa","slug":"LoRa","permalink":"http://yoursite.com/categories/LoRa/"}],"tags":[{"name":"LoRa","slug":"LoRa","permalink":"http://yoursite.com/tags/LoRa/"}]},{"title":"C++.h和.cpp","slug":"C-h和-cpp","date":"2020-07-13T03:04:52.000Z","updated":"2020-07-14T14:31:35.469Z","comments":true,"path":"2020/07/13/C-h和-cpp/","link":"","permalink":"http://yoursite.com/2020/07/13/C-h和-cpp/","excerpt":"C++的.h文件和.cpp文件各应该包含什么内容","text":"C++的.h文件和.cpp文件各应该包含什么内容 .h文件类的声明，成员函数声明… 记得在头部添加： 123#ifndef XXXX_H //这里如果头文件名为LoraNode.h, 则写为LORANODE_H#define XXXX_H#pragma once //这个一般在创建头文件的时候会自动添加 尾部添加： 1#endif 目的是为了防止重复编译而报错 .cpp文件填写类成员函数的定义 首先引用头文件 1#include \"xxxx.h\" 注：不用再重写class Name{}，否则会报错为class重定义，直接使用::进行外部定义类成员函数即可 例： 123double LoraNode::th(si)&#123;...&#125;","categories":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"将Unity场景导入到LayaAir","slug":"将Unity场景导入到LayaAir","date":"2020-07-09T01:02:46.000Z","updated":"2020-07-16T02:31:04.841Z","comments":true,"path":"2020/07/09/将Unity场景导入到LayaAir/","link":"","permalink":"http://yoursite.com/2020/07/09/将Unity场景导入到LayaAir/","excerpt":"","text":"将U3D插件拖拽到Unity项目的Assets目录下，会自动在项目中import LayaAir3D选项 LayaAir3d-&gt;Export Tool中可以导出Unity Scene 导出到laya工程下的bin-&gt;res文件夹 LayaAir3D-&gt;Help-&gt;Tutorial可看哪些是能够兼容的 骨骼动画： spine骨骼动画工具 骨骼动画: 把动画打散, 通过工具，调骨骼的运动等来形成动画spine是一个非常流行的2D骨骼动画制作工具spine 动画美术人员导出3个文件: (1) .png文件:动画的”骨骼”的图片集; (2).atlas文件: 每个骨骼在图片集里面位置，大小; (3).json文件: 骨骼动画的anim控制文件,以及骨骼位置等信息;骨骼动画导入: 直接把三个文件拷贝到项目的资源目录下即可;使用骨骼动画 2种方式: (1) 直接拖动到场景; (2) 创建一个节点来添加sp.Skeleton组件; Unity的骨骼动画：Unity导入骨骼动画时需要的源文件也是spine导出的： .atlas .json .png三个文件，不过需要将.atlas重命名为.atlas.txt Laya的骨骼动画：Laya的骨骼动画在导入的时候是直接对接Spine导出的骨骼动画格式的，即.atlas .json .png三个文件","categories":[{"name":"Laya","slug":"Laya","permalink":"http://yoursite.com/categories/Laya/"}],"tags":[{"name":"Environment","slug":"Environment","permalink":"http://yoursite.com/tags/Environment/"}]},{"title":"为Sublime添加TypeScript高亮支持","slug":"为Sublime添加TypeScript高亮支持","date":"2020-07-09T00:50:23.000Z","updated":"2020-07-09T13:13:28.033Z","comments":true,"path":"2020/07/09/为Sublime添加TypeScript高亮支持/","link":"","permalink":"http://yoursite.com/2020/07/09/为Sublime添加TypeScript高亮支持/","excerpt":"","text":"首先在cmd或者Git CMD安装typescript编译支持：npm install -g typescript 若出现npm ERR! code EINTEGRITY报错： npm cache verify 打开sublime安装package control：在sublime中ctrl+shift+p打开命令面板 输入ip查找Package Control: Installl Package 打开package control安装TypeScript：打开preference-&gt;package control，然后继续查找TypeScript进行安装","categories":[{"name":"Laya","slug":"Laya","permalink":"http://yoursite.com/categories/Laya/"}],"tags":[{"name":"Environment","slug":"Environment","permalink":"http://yoursite.com/tags/Environment/"}]},{"title":"UnitySprite","slug":"UnitySprite","date":"2020-07-08T01:35:52.000Z","updated":"2020-07-08T07:28:17.674Z","comments":true,"path":"2020/07/08/UnitySprite/","link":"","permalink":"http://yoursite.com/2020/07/08/UnitySprite/","excerpt":"Sprite相关","text":"Sprite相关 Sprite RendererFlip：勾选后图片会在X或Y轴方向上翻转 Material:材质，默认是Sprites - Default，场景中的灯光不会影响到图片，改为Default - Diffuse，灯光可以照亮图片 Draw Mode：绘图模式, 普通，拉伸，平铺 Sorting Layer：分类层，控制图片的渲染顺序，点开Sorting Layer，越靠下的越后渲染，越在最前面，挡住后面的图片 Order In Layer：在同一层中的次序，当图片在同一个层下时，设置此数值可以再次控制渲染顺序 Mask Interaction：遮罩交互 打包图集Editor-&gt;Project Settings-&gt;Editor下面有sprite packer的模式。Disabled表示不启用它，Enabled For Builds 表示只有打包的时候才会启用它，Always Enabled 表示永远启用它。 这里的启用它就表示是否将小图自动打成图集。 .prefab文件 .prefab文件在Unity引擎中，扮演着配置文件的作用，用它将多个组件关联在了一起，组成了一个整体，默认是一个二进制文件 .meta文件新的资源导入Unity时，Unity会自动做下面这件事： 1.分配唯一ID 2.创建.meta文件 3.处理资源 .meta文件包含内容： guid：分配的唯一ID存在这里 MonoImporter：它的数据是不同的ImprotSetting数据，比如Mode Improter，Audio Improter等等，对照Inspector面板就可以看懂每行数据","categories":[{"name":"Unity","slug":"Unity","permalink":"http://yoursite.com/categories/Unity/"}],"tags":[{"name":"Sprite","slug":"Sprite","permalink":"http://yoursite.com/tags/Sprite/"},{"name":"Unity","slug":"Unity","permalink":"http://yoursite.com/tags/Unity/"}]},{"title":"ProjectTiny爬坑记录","slug":"ProjectTiny爬坑记录","date":"2020-07-07T13:23:22.000Z","updated":"2020-07-07T13:23:22.160Z","comments":true,"path":"2020/07/07/ProjectTiny爬坑记录/","link":"","permalink":"http://yoursite.com/2020/07/07/ProjectTiny爬坑记录/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"ProjectTinyWorkshop核心知识点","slug":"ProjectTinyWorkshop核心知识点","date":"2020-07-07T13:03:53.000Z","updated":"2020-07-07T13:13:14.545Z","comments":true,"path":"2020/07/07/ProjectTinyWorkshop核心知识点/","link":"","permalink":"http://yoursite.com/2020/07/07/ProjectTinyWorkshop核心知识点/","excerpt":"ECS & Monobehaviours","text":"ECS & Monobehaviours Monobehaviours: C#类，引用类型，数据分散在内存中，当数据取回时，系统需要遍历内存去寻找，操作时不需要的数据也被处理 ECS: 使用值类型，数据会在内存中紧密地装在一块(chunk)，仅处理需要操作的数据 Entities只是帮助我们找到(component)数据的handle Components举例：(Component只是模块化的数据) 123456789101112struct Health : IComponentData&#123; int current; int max;&#125;struct Sprite2D : IComponentData&#123; Entity image; Rect imageRegion; Vector2 pivot;&#125; Entities举例： 比如某个Entity 1有四个组件(Component)，LocalPosition组件，Sprite2DRenderer组件，Health组件，Player组件（这里没有行为，行为由系统（System）给出） Systems不在乎它处理的生命值是玩家的生命值还是一个兽人或者哥布林的生命值 Systems包括两部分，一是query，帮我找到这个数据，那个数据…，找到了之后对数据的action 用System的方式筛选要操作的rntities: 123456789101112public override void OnUpdate()&#123; var dt = Scheduler.DeltaTime(); ForEach( LocalPosition MoveToTarget Not : Frozen =&gt; //注意查询时的这种筛选，用Not &#123; //actions &#125; );&#125;","categories":[{"name":"Project Tiny","slug":"Project-Tiny","permalink":"http://yoursite.com/categories/Project-Tiny/"}],"tags":[{"name":"DOTS","slug":"DOTS","permalink":"http://yoursite.com/tags/DOTS/"}]},{"title":"Unity DOTS(直播笔记)","slug":"UnityDOTS(直播笔记)","date":"2020-07-07T12:52:13.000Z","updated":"2020-07-07T13:10:30.304Z","comments":true,"path":"2020/07/07/UnityDOTS(直播笔记)/","link":"","permalink":"http://yoursite.com/2020/07/07/UnityDOTS(直播笔记)/","excerpt":"ECS优化缓存行-- ECS和传统游戏对象-- 原型Archtype-- 栈帧-- 组件与共享组件-- ECS实例-- 汇编指令-- SIMD-- Burst编译器-- Unity.mathematics数学库-- Job多线程计算-- 系统生命周期--","text":"ECS优化缓存行-- ECS和传统游戏对象-- 原型Archtype-- 栈帧-- 组件与共享组件-- ECS实例-- 汇编指令-- SIMD-- Burst编译器-- Unity.mathematics数学库-- Job多线程计算-- 系统生命周期-- ECS优化缓存行：怎样提高缓冲区命中率，每个对象只加载xy坐标和旋转一共12b，那么一个缓存行能存五个对象，浪费64-21*5 = 4b ECS和传统游戏对象：ECS：Entity（实体）、Component（组件）、System（系统） 传统： 12345678public class Game : MonoBehaviour&#123; public int x; private void Update() &#123; x++; &#125;&#125; ECS： 123456789101112131415public struct GameComponentData : IComponentData // 组件 //结构体只保存数据，不能写逻辑&#123; public int x;&#125;public class MyGameSystem : ComponentSystem //在System里找关心的组件&#123; protected override void OnUpdate() &#123; this.Entities.ForEach((ref GameComponentData data) =&gt; &#123; data.x++; &#125;); &#125;&#125; 原型Archtype：即使不同的实体Entity，只要组件相同都会保存在原型ArcheType。 ArcheType是16KB的数组容器。 栈帧：栈上会保留值类型数据和指向堆的指针。 组件与共享组件：值类型组件和共享类型组件。 System可以找到它关心的组件去遍历。 Component System在Main Thread，Job Component System(JCS)可以在多线程。 Main Thread–JCS &gt;&gt;&gt; Worker Thread–Job, Job, Job…… JobSystem应用：ECS实例：ArcheType Chunk容量16KB，包含Trees #1, Trees #2, Rocks #1, Big Enemies #1, Small Enemies #1, Small Enemies #2, Query出符合条件的实体组件，大敌人、小敌人统一Update（相比Rocks，Trees更感兴趣） 汇编指令：mov指令：内存中数据传到寄存器/寄存器数据传到另一寄存器 mov ax 8 数据-&gt;寄存器 mov ax bx 寄存器-&gt;寄存器 SIMD：没听懂用来干嘛 SIMD指令优化总结： 避免代码出现分支预测（会打断SIMD的向量化指令），使用math.select和math.lerp代替分支预测 使用float4 bool4等代替float bool 使用m128自己组织128位数据 编译后尽量使用v开头指令，结尾尽量是ps指令而不是ss指令 Burst编译器：Burst只支持值类型数据的编译，不支持引用类型数据编译（因为C#的GC做的不好）。 Burst编译器是以LLVM为基础的后端编译技术。 怎么启动Burst编译器？在Job上面加上[BurstCompile]，如果在Job外怎么工作呢？使用有一个限制是需要静态方法 12345678910111213141516[BurstCompile]public class MyClass&#123; [BurstCompile] public static float add(float a, float b) &#123; return a * b; &#125; [BurstCompile] &#123; public static unsafe void dot(float3* a, float3* b, float* c) &#123; *c = math.dot(*a, *b); &#125; &#125;&#125; Unity.mathematics数学库：提供矢量类型（float4 float3…）可直接映射到硬件SIMD寄存器 Math类也提供了直接映射到硬件SIMD寄存器 原本CPU一个一个计算的有了SIMD可以一次性计算 Job多线程计算：12345678910111213141516171819202122[BurstCompile]public struct MyJob1 : IJob&#123; [ReadOnly] public int left; [ReadOnly] public int right; [WriteOnly] public NativeArray&lt;int&gt; @out; public Execute() &#123; @out[0] = left * right; &#125;&#125;private void Start()&#123; MyJob1 myJob = new MyJob1(); myJob.left = 2; myJob.right = 3; myJob.@out = new NativeArray&lt;int&gt;(1, Allocator.TempJob); myJob.Schedule().Complete(); //在一个子线程中计算并且等待完成 Debug.Log(myJob.@out[0]); // log 6; myJob.@out.Dispose();&#125; 1234567891011121314151617181920212223// IJobFor[BurstCompile]public struct MyJob2 : IJobFor&#123; public NativeArray&lt;int&gt; left; [ReadOnly] public NativeArra&lt;int&gt; right; public void Execute(int index) &#123; left[index] = left[index] * right[index]; //输出线程ID和当前执行的索引 Debug.Log(System.Threading.Thread.CurrentThread.ManagedThreadId + &quot;,&quot; + index); &#125;&#125;private void start()&#123; MyJob2 myJob = new MyJob2(); myJob.left = new NativeArray&lt;int&gt;(100, Allocator.TempJob); myJob.right = new NativeArray&lt;int&gt;(100, Allocator.TempJob); myJob.Schedule(myJob.left.Length, new JobHandle()).Complete(); //实际上是在一个子线程里面开了个for循环，Schedule是在一个子线程中执行，可以保证顺序 myJob.left.Dispose(); myJob.right.Dispose();&#125; Schedule和ScheduleParallel对比： 12//ScheduleParallel可以在多个子线程中并行运行，不保证顺序myJob.ScheduleParallel(myJob.left.Length, 64, new JobHandle()).Complete(); IJobFor和IJobParallelFor 1234567891011121314151617181920212223[BurstCompile]public struct MyJob2 : IJobParallelFor&#123; public NativeArray&lt;int&gt; left; [ReadOnly] public NativeArra&lt;int&gt; right; public void Execute(int index) &#123; left[index] = left[index] * right[index]; //输出线程ID和当前执行的索引 Debug.Log(System.Threading.Thread.CurrentThread.ManagedThreadId + &quot;,&quot; + index); &#125;&#125;private void start()&#123; MyJob2 myJob = new MyJob2(); myJob.left = new NativeArray&lt;int&gt;(100, Allocator.TempJob); myJob.right = new NativeArray&lt;int&gt;(100, Allocator.TempJob); //因为接口是IJobParallelFor，这里的Schedule就完全是并行执行不保证顺序了(注意参数有些不同，多了个“64”) myJob.Schedule(myJob.left.Length, 64, new JobHandle()).Complete(); myJob.left.Dispose(); myJob.right.Dispose();&#125; Complete是实现在主线程等待执行的结果 myJob.Schedule和myJob.Run对比：Schedule是在多核子线程中并行计算，Run是完全在主线程执行 Job的处理依赖关系： 我有Job1和Job2，怎么并行执行快一些？ 1234567891011121314151617MyJob2 myJob1 = new MyJob2();MyJob3 myJob2 = new MyJob3();//同时并行执行myJob1.Schedule(100, 64);myJob2.Schedule(100, 64);//Job1执行完毕后再并行执行Job2//缺点是要在主线程等待Job1结束(因为用了Complete())myJob1.Schedule(100, 64).Complete();myJob2.Schedule(100, 64); //设置Job2依赖Job1，这样不需要在主线程等待//JobHandle和依赖项：调用Schedule方法时会返回JobHandle，可以用Job1的JobHandle作为Job2的依赖项JobHandle jobHandle = new JobHandle();JobHandle scheduleJobDependencyJob = myJob1.Schedule(100, 64, jobHandle);myJob2.Schedule(100, 64, scheduleJobDependencyJob).Complete(); 设计模式-组合模式：系统生命周期：OnCreate(), OnStartRunning(), OnUpdate(), OnStopRunning(), OnDestory()","categories":[{"name":"Unity","slug":"Unity","permalink":"http://yoursite.com/categories/Unity/"}],"tags":[{"name":"DOTS","slug":"DOTS","permalink":"http://yoursite.com/tags/DOTS/"}]},{"title":"本地代码提交至git","slug":"本地代码提交至git","date":"2019-11-20T15:02:36.000Z","updated":"2020-07-07T12:54:25.438Z","comments":true,"path":"2019/11/20/本地代码提交至git/","link":"","permalink":"http://yoursite.com/2019/11/20/本地代码提交至git/","excerpt":"本地更新如何提交至GitHub","text":"本地更新如何提交至GitHub for first use1234567git init ***init .git*** git status ***check files to be added to the local repository*** git add xxx ***add files to repo*** git commit -m &quot;commit description&quot; ***commit to repo*** git remote add origin git@github.com:mobinets/hyblora.git ***link local repo to github*** git pull --rebase origin master ***pull = fetch + merge*** git push -u origin master ***upload*** not first use repo123git add xxx git commit -m &quot;commit discription&quot; git push -u origin master","categories":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/categories/Git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"ParticalFilter(粒子滤波算法)","slug":"ParticalFilter(粒子滤波算法)","date":"2019-09-23T05:36:58.000Z","updated":"2020-07-07T04:04:58.469Z","comments":true,"path":"2019/09/23/ParticalFilter(粒子滤波算法)/","link":"","permalink":"http://yoursite.com/2019/09/23/ParticalFilter(粒子滤波算法)/","excerpt":"粒子滤波算法","text":"粒子滤波算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182import numpy as npimport scipy as scipyfrom numpy.random import uniformimport scipy.statsnp.set_printoptions(threshold=3)np.set_printoptions(suppress=True)import cv2def drawLines(img, points, r, g, b): cv2.polylines(img, [np.int32(points)], isClosed=False, color=(r, g, b))def drawCross(img, center, r, g, b): d = 5 t = 2 LINE_AA = cv2.LINE_AA if cv2.__version__[0] == '3' else cv2.CV_AA color = (r, g, b) ctrx = center[0,0] ctry = center[0,1] cv2.line(img, (ctrx - d, ctry - d), (ctrx + d, ctry + d), color, t, LINE_AA) cv2.line(img, (ctrx + d, ctry - d), (ctrx - d, ctry + d), color, t, LINE_AA) def mouseCallback(event, x, y, flags,null): global center global trajectory global previous_x global previous_y global zs center=np.array([[x,y]]) trajectory=np.vstack((trajectory,np.array([x,y]))) #noise=sensorSigma * np.random.randn(1,2) + sensorMu if previous_x &gt;0: heading=np.arctan2(np.array([y-previous_y]), np.array([previous_x-x ])) if heading&gt;0: heading=-(heading-np.pi) else: heading=-(np.pi+heading) distance=np.linalg.norm(np.array([[previous_x,previous_y]])-np.array([[x,y]]) ,axis=1) std=np.array([2,4]) u=np.array([heading,distance]) predict(particles, u, std, dt=1.) zs = (np.linalg.norm(landmarks - center, axis=1) + (np.random.randn(NL) * sensor_std_err)) update(particles, weights, z=zs, R=50, landmarks=landmarks) indexes = systematic_resample(weights) resample_from_index(particles, weights, indexes) previous_x=x previous_y=y WIDTH=800HEIGHT=600WINDOW_NAME=\"Particle Filter\"#sensorMu=0#sensorSigma=3sensor_std_err=5def create_uniform_particles(x_range, y_range, N): particles = np.empty((N, 2)) particles[:, 0] = uniform(x_range[0], x_range[1], size=N) particles[:, 1] = uniform(y_range[0], y_range[1], size=N) return particlesdef predict(particles, u, std, dt=1.): N = len(particles) dist = (u[1] * dt) + (np.random.randn(N) * std[1]) particles[:, 0] += np.cos(u[0]) * dist particles[:, 1] += np.sin(u[0]) * dist def update(particles, weights, z, R, landmarks): weights.fill(1.) for i, landmark in enumerate(landmarks): distance=np.power((particles[:,0] - landmark[0])**2 +(particles[:,1] - landmark[1])**2,0.5) weights *= scipy.stats.norm(distance, R).pdf(z[i]) weights += 1.e-300 # avoid round-off to zero weights /= sum(weights) def neff(weights): return 1. / np.sum(np.square(weights))def systematic_resample(weights): N = len(weights) positions = (np.arange(N) + np.random.random()) / N indexes = np.zeros(N, 'i') cumulative_sum = np.cumsum(weights) i, j = 0, 0 while i &lt; N and j&lt;N: if positions[i] &lt; cumulative_sum[j]: indexes[i] = j i += 1 else: j += 1 return indexes def estimate(particles, weights): pos = particles[:, 0:1] mean = np.average(pos, weights=weights, axis=0) var = np.average((pos - mean)**2, weights=weights, axis=0) return mean, vardef resample_from_index(particles, weights, indexes): particles[:] = particles[indexes] weights[:] = weights[indexes] weights /= np.sum(weights) x_range=np.array([0,800])y_range=np.array([0,600])#Number of partcilesN=400landmarks=np.array([ [144,73], [410,13], [336,175], [718,159], [178,484], [665,464] ])NL = len(landmarks)particles=create_uniform_particles(x_range, y_range, N)weights = np.array([1.0]*N)# Create a black image, a window and bind the function to windowimg = np.zeros((HEIGHT,WIDTH,3), np.uint8)cv2.namedWindow(WINDOW_NAME)cv2.setMouseCallback(WINDOW_NAME,mouseCallback)center=np.array([[-10,-10]])trajectory=np.zeros(shape=(0,2))robot_pos=np.zeros(shape=(0,2))previous_x=-1previous_y=-1DELAY_MSEC=50while(1): cv2.imshow(WINDOW_NAME,img) img = np.zeros((HEIGHT,WIDTH,3), np.uint8) drawLines(img, trajectory, 0, 255, 0) drawCross(img, center, r=255, g=0, b=0) #landmarks for landmark in landmarks: cv2.circle(img,tuple(landmark),10,(255,0,0),-1) #draw_particles: for particle in particles: cv2.circle(img,tuple((int(particle[0]),int(particle[1]))),1,(255,255,255),-1) if cv2.waitKey(DELAY_MSEC) &amp; 0xFF == 27: break cv2.circle(img,(10,10),10,(255,0,0),-1) cv2.circle(img,(10,30),3,(255,255,255),-1) cv2.putText(img,\"Landmarks\",(30,20),1,1.0,(255,0,0)) cv2.putText(img,\"Particles\",(30,40),1,1.0,(255,255,255)) cv2.putText(img,\"Robot Trajectory(Ground truth)\",(30,60),1,1.0,(0,255,0)) drawLines(img, np.array([[10,55],[25,55]]), 0, 255, 0) cv2.destroyAllWindows() 如何安装依赖并运行打开anaconda prompt 1234conda create -n Filters python=3conda activate Filtersconda install -c menpo opencv3conda install numpy scipy matplotlib sympy cd python_codepython partical.pypython partical_v2.py","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Hexo发布","slug":"Hexo发布","date":"2019-09-14T15:52:50.000Z","updated":"2020-07-07T06:13:42.138Z","comments":true,"path":"2019/09/14/Hexo发布/","link":"","permalink":"http://yoursite.com/2019/09/14/Hexo发布/","excerpt":"如何发布Hexo博客","text":"如何发布Hexo博客 hexo文件夹中，git bash here hexo new ‘’ hexo clean hexo g hexo d","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"Python---yield关键字","slug":"Python的yield关键字","date":"2019-07-25T06:59:22.000Z","updated":"2020-07-07T03:59:33.769Z","comments":true,"path":"2019/07/25/Python的yield关键字/","link":"","permalink":"http://yoursite.com/2019/07/25/Python的yield关键字/","excerpt":"python中yield关键字的用法","text":"python中yield关键字的用法 迭代(iteration)与可迭代(iterable)使用容器时逐个获取元素的过程为迭代。 哪些类型是可迭代的 python中的顺序类型： list, tuple(元组，列表可修改元组不可修改，列表用中括号元组用小括号), string. dict, set, file. 某类对象提供了 __iter__() 或者 __getitem__() 方法. 迭代器对迭代器不断调用next()方法，可依次获取下一个元素，迭代器__iter__()方法返回迭代器自身，因此迭代器也是可迭代的。 迭代器协议(iterator protocol)一个容器提供__iter__()方法，该方法能返回一个能逐个访问容器内所有元素的迭代器，则该容器实现了迭代器协议。 python处理for循环的过程12for x in something: print(x) 处理for循环首先调用内建函数iter(something),内建函数调用something.__iter__(),返回something对应的迭代器，然后for循环会调用内建函数next()，作用在迭代器上获取迭代器的下一个元素，并赋值给x 生成器函数(generaor function)和生成器(generator)如果一个函数包含 yield 表达式，那么它是一个生成器函数；调用它会返回一个特殊的迭代器，称为生成器。 生成器函数被调用后，其函数体内的代码并不会立即执行，而是返回一个生成器（generator-iterator）。当返回的生成器调用成员方法时，相应的生成器函数中的代码才会执行。 “下一个yield表达式”调用 generator.next() 时，生成器函数会从当前位置开始执行到下一个 yield 表达式。这里的「下一个」指的是执行逻辑的下一个。 12345678910111213141516def f123(): yield 1 yield 2 yield 3for item in f123(): # 1, 2, and 3, will be printed print(item)def f13(): yield 1 while False: yield 2 yield 3for item in f13(): # 1 and 3, will be printed print(item) 使用 send() 方法与生成器函数通信12345678910def func(): x = 1 while True: y = (yield x) x += ygeniter = func()geniter.next() # 1geniter.send(3) # 4geniter.send(10)# 14 生成器函数 func 用 yield 表达式，将处理好的 x 发送给生成器的调用者；与此同时，生成器的调用者通过 send 函数，将外部信息作为生成器函数内部的 yield 表达式的值，保存在 y 当中，并参与后续的处理。 yield的好处顺序访问容器内的前五个元素： way1:获取所有元素然后取前五 way2:逐个迭代，至第五个元素 假设对于一个func(),返回值为列表，调用者对其返回值只有逐个迭代： 若等函数生成所有元素可能需要很长时间 使用yield把func()变成一个生成器函数，每次产生一个元素，可以节省开销","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Gradle相关知识(转载自Bonker)","slug":"Gradle相关知识(转载自Bonker)","date":"2019-07-18T08:38:29.000Z","updated":"2020-07-07T06:13:05.470Z","comments":true,"path":"2019/07/18/Gradle相关知识(转载自Bonker)/","link":"","permalink":"http://yoursite.com/2019/07/18/Gradle相关知识(转载自Bonker)/","excerpt":"关于Android开发中的Gradle","text":"关于Android开发中的Gradle (转载自Bonker）原文链接：https://www.cnblogs.com/Bonker/p/5619458.html 什么是Gradle简单的说，Gradle是一个构建工具，它是用来帮助我们构建app的，构建包括编译、打包等过程。我们可以为Gradle指定构建规则，然后它就会根据我们的“命令”自动为我们构建app。Android Studio中默认就使用Gradle来完成应用的构建。有些同学可能会有疑问：”我用AS不记得给Gradle指定过什么构建规则呀，最后不还是能搞出来个apk。“ 实际上，app的构建过程是大同小异的，有一些过程是”通用“的，也就是每个app的构建都要经历一些公共步骤。因此，在我们在创建工程时，Android Studio自动帮我们生成了一些通用构建规则，很多时候我们甚至完全不用修改这些规则就能完成我们app的构建。 有些时候，我们会有一些个性化的构建需求，比如我们引入了第三方库，或者我们想要在通用构建过程中做一些其他的事情，这时我们就要自己在系统默认构建规则上做一些修改。这时候我们就要自己向Gradle”下命令“了，这时候我们就需要用Gradle能听懂的话了，也就是Groovy。Groovy是一种基于JVM的动态语言，关于它的具体介绍，感兴趣的同学可以文末参考”延伸阅读“部分给出的链接。 我们在开头处提到“Gradle是一种构建工具”。实际上，当我们想要更灵活的构建过程时，Gradle就成为了一个编程框架——我们可以通过编程让构建过程按我们的意愿进行。也就是说，当我们把Gradle作为构建工具使用时，我们只需要掌握它的配置脚本的基本写法就OK了；而当我们需要对构建流程进行高度定制时，就务必要掌握Groovy等相关知识了。限于篇幅，本文只从构建工具使用者的角度来介绍Gradle的一些最佳实践，在文末“延伸阅读”部分给出了几篇高质量的深入介绍Gradle的文章，其中包含了Groovy等知识的介绍。 Gradle的基本组分Project与Task在Gradle中，每一个待构建的工程是一个Project，构建一个Project需要执行一系列Task，比如编译、打包这些构建过程的子过程都对应着一个Task。具体来说，一个apk文件的构建包含以下Task：Java源码编译、资源文件编译、Lint检查、打包以生成最终的apk文件等等。 插件插件的核心工作有两个：一是定义Task；而是执行Task。也就是说，我们想让Gradle能正常工作，完成整个构建流程中的一系列Task的执行，必须导入合适的插件，这些插件中定义了构建Project中的一系列Task，并且负责执行相应的Task。 在新建工程的app模块的build.gradle文件的第一行，往往都是如下这句： apply plugin: ‘com.android.application’这句话的意思就是应用“com.android.application“这个插件来构建app模块，app模块就是Gradle中的一个Project。也就是说，这个插件负责定义并执行Java源码编译、资源文件编译、打包等一系列Task。实际上”com.android.application”整个插件中定义了如下4个顶级任务： assemble: 构建项目的输出（apk） check: 进行校验工作 build: 执行assemble任务与check任务 clean: 清除项目的输出 当我们执行一个任务时，会自动执行它所依赖的任务。比如，执行assemble任务会执行assembleDebug任务和assembleRelease任务，这是因为一个Android项目至少要有debug和release这两个版本的输出。 Gradle配置文件我们在Android Studio中新建一个工程，可以得到如下的工程结构图： 上面我们说过，Android Studio中的一个Module即为Gradle中的一个Project。上图的app目录下，存在一个build.gradle文件，代表了app Module的构建脚本，它定义了应用于本模块的构建规则。我们可以看到，工程根目录下也存在一个build.gradle文件，它代表了整个工程的构建，其中定义了适用于这个工程中所有模块的构建规则。 接下来我们介绍一下上图中其他几个Gradle配置文件： gradle.properties: 从它的名字可以看出，这个文件中定义了一系列“属性”。实际上，这个文件中定义了一系列供build.gradle使用的常量，比如keystore的存储路径、keyalias等等。 gradlew与gradlew.bat: gradlew为Linux下的shell脚本，gradlew.bat是Windows下的批处理文件。gradlew是gradle wrapper的缩写，也就是说它对gradle的命令进行了包装，比如我们进入到指定Module目录并执行“gradlew.bat assemble”即可完成对当前Module的构建（Windows系统下）。 local.properties: 从名字就可以看出来，这个文件中定义了一些本地属性，比如SDK的路径。 settings.gradle: 假如我们的项目包含了不只一个Module时，我们想要一次性构建所有Module以完成整个项目的构建，这时我们需要用到这个文件。比如我们的项目包含了ModuleA和ModuleB这两个模块，则这个文件中会包含这样的语句：include ‘:ModuleA’, ‘:ModuleB’。 构建脚本首先我们来看一下工程目录下的build.gradle，它指定了真个整个项目的构建规则，它的内容如下： &#123;123456789101112131415 repositories &#123; jcenter() //构建脚本中所依赖的库都在jcenter仓库下载 &#125; dependencies &#123; //指定了gradle插件的版本 classpath &apos;com.android.tools.build:gradle:1.5.0&apos; &#125;&#125;allprojects &#123; repositories &#123; //当前项目所有模块所依赖的库都在jcenter仓库下载 jcenter() &#125;&#125; 我们再来简单介绍下app模块的build.gradle的内容： 12345678910111213141516171819202122232425262728//加载用于构建Android项目的插件apply plugin: &apos;com.android.application&apos;android &#123; //构建Android项目使用的配置 compileSdkVersion 23 //指定编译项目时使用的SDK版本 buildToolsVersion &quot;23.0.1&quot; //指定构建工具的版本 defaultConfig &#123; applicationId &quot;com.absfree.debugframwork&quot; //包名 minSdkVersion 15 //指定支持的最小SDK版本 targetSdkVersion 23 //针对的目标SDK版本 versionCode 1 versionName &quot;1.0&quot; &#125; buildTypes &#123; //针对不同的构建版本进行一些设置 release &#123; //对release版本进行的设置 minifyEnabled false //是否开启混淆 proguardFiles getDefaultProguardFile(&apos;proguard-android.txt&apos;), &apos;proguard-rules.pro&apos; //指定混淆文件的位置 &#125; &#125;&#125;dependencies &#123; //指定当前模块的依赖 compile fileTree(dir: &apos;libs&apos;, include: [&apos;*.jar&apos;]) testCompile &apos;junit:junit:4.12&apos; compile &apos;com.android.support:appcompat-v7:23.1.1&apos; compile &apos;com.android.support:design:23.1.1&apos;&#125; 常见配置整个工程的build.gradle通常不需我们改动，这里我们介绍下一些对模块目录下build.gradle文件的常见配置。 依赖第三方库当我们的项目中用到了了一些第三方库时，我们就需要进行一些配置，以保证能正确导入相关依赖。设置方法很简单，比如我们在app模块中中用到了Fresco，只需要在build.gradle文件中的dependencies块添加如下语句： 1234dependencies &#123; ... compile &apos;com.facebook.fresco:fresco:0.11.0&apos;&#125; 这样一来，Gradle会自动从jcenter仓库下载我们所需的第三方库并导入到项目中。 导入本地jar包在使用第三方库时，除了像上面那样从jcenter仓库下载，我们还可以导入本地的jar包。配置方法也很简单，只需要先把jar文件添加到app\\libs目录下，然后在相应jar文件上单击右键，选择“Ad As Library”。然后在build.gradle的dependencies块下添加如下语句： compile files(‘libs/xxx.jar’)实际上我们可以看到，系统为我们创建的build.gradle中就已经包含了如下语句： compile fileTree(dir: ‘libs’, include: [‘*.jar’]) 这句话的意思是，将libs目录下的所有jar包都导入。所以实际上我们只需要把jar包添加到libs目录下并“Ad As Library”即可。 依赖其它模块假设我们的项目包含了多个模块，并且app模块依赖other模块，那么我们只需app\\build.gradle的denpendencies块下添加如下语句： compile project(‘:other’) 构建输出为aar文件通常我们构建的输出目标都是apk文件，但如果我们的当前项目时Android Library，我们的目标输出就是aar文件。要想达到这个目的也很容易，只需要把build.gradle的第一句改为如下： apply plugin:’com.android.library’这话表示我们使用的插件不再是构建Android应用的插件，而是构建Android Library的插件，这个插件定义并执行用于构建Android Library的一系列Task。 自动移除不再使用的资源只需进行如下配置： 1234567891011android &#123; ... &#125; buildTypes &#123; release &#123; ... shrinkResources true ... &#125; &#125;&#125; 忽略Lint错误在我们构建Android项目的过程中，有时候会由于Lint错误而终止。当这些错误来自第三方库中时，我们往往想要忽略这些错误从而继续构建进程。这时候，我们可以只需进行如下配置： 123456android &#123; ... lintOptions &#123; abortOnError false &#125;&#125; 集成签名配置在构建release版本的Android项目时，每次都手动导入签名文件，键入密码、keyalias等信息十分麻烦。通过将签名配置集成到构建脚本中，我们就不必每次构建发行版本时都手动设置了。具体配置如下： 1234567891011121314151617signingConfigs &#123; myConfig &#123; //将&quot;xx&quot;替换为自己的签名文件信息 storeFile file(&quot;xx.jks&quot;) storePassword &quot;xx&quot; keyAlias &quot;xx&quot; keyPassword &quot;xx&quot; &#125;&#125;android &#123; buildTypes &#123; release &#123; signingConfig signingConfigs.myConfig //在release块中加入这行 ... &#125; &#125; ...&#125; 真实开发中，我们不应该把密码等信息直接写到build.gradle中，更好的做法是放在gradle.properties中设置： 1234RELEASE_STOREFILE=xxx.jks RELEASE_STORE_PASSWORD = xxxRELEASE_KEY_ALIAS=xxxRELEASE_KEY_PASSWORD=xxx 然后在build.gradle中直接引用即可： 12345678signingConfigs &#123; myConfig &#123; storeFilefile(RELEASE_STOREFILE) storePassword RELEASE_STORE_PASSWORD keyAlias RELEASE_KEY_ALIAS keyPassword RELEASE_KEY_PASSWORD &#125;&#125; 关于Gradle的其他配置方法大家可以参考“延伸阅读”部分的“Gradle最佳实践”。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"http://yoursite.com/tags/Gradle/"}]},{"title":"Linux远程登录及服务器配置","slug":"Linux远程登录","date":"2019-07-17T13:45:43.000Z","updated":"2020-07-07T03:58:51.303Z","comments":true,"path":"2019/07/17/Linux远程登录/","link":"","permalink":"http://yoursite.com/2019/07/17/Linux远程登录/","excerpt":"Linux远程登录及服务器配置","text":"Linux远程登录及服务器配置 ##Linux远程登录原理安装telnet远程客户端登录工具的客户机通过23（默认）端口连接到Linux服务器，通过telnet将远程客户机上命令传到服务器执行并反馈。###telnet软件包安装sudo apt-get install inetutils-telnetd(ubuntu没有默认安装Telnet软件包)","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"远程登录","slug":"远程登录","permalink":"http://yoursite.com/tags/远程登录/"}]},{"title":"可见光认证相关","slug":"可见光认证","date":"2019-07-05T03:09:43.000Z","updated":"2020-07-07T04:06:45.767Z","comments":true,"path":"2019/07/05/可见光认证/","link":"","permalink":"http://yoursite.com/2019/07/05/可见光认证/","excerpt":"基于可见光的无线网络认证","text":"基于可见光的无线网络认证 2019-07-05 802.1x认证过程： 当用户有访问网络需求时打开802.1X客户端程序，输入已经申请、登记过的用户名和密码，发起连接请求（EAPOL-Start报文）。此时，客户端程序将发出请求认证的报文给设备端，开始启动一次认证过程。 设备端收到请求认证的数据帧后，将发出一个请求帧（EAP-Request/Identity报文）要求用户的客户端程序发送输入的用户名。 客户端程序响应设备端发出的请求，将用户名信息通过数据帧（EAP-Response/Identity报文）发送给设备端。设备端将客户端发送的数据帧经过封包处理后（RADIUS Access-Request报文）送给认证服务器进行处理。 RADIUS服务器收到设备端转发的用户名信息后，将该信息与数据库中的用户名表对比，找到该用户名对应的密码信息，用随机生成的一个加密字对它进行加密处理，同时也将此加密字通过RADIUS Access-Challenge报文发送给设备端，由设备端转发给客户端程序。 客户端程序收到由设备端传来的加密字（EAP-Request/MD5 Challenge报文）后，用该加密字对密码部分进行加密处理（此种加密算法通常是不可逆的），生成EAP-Response/MD5 Challenge报文，并通过设备端传给认证服务器。 RADIUS服务器将收到的已加密的密码信息（RADIUS Access-Request报文）和本地经过加密运算后的密码信息进行对比，如果相同，则认为该用户为合法用户，反馈认证通过的消息（RADIUS Access-Accept报文和EAP-Success报文）。 设备收到认证通过消息后将端口改为授权状态，允许用户通过端口访问网络。在此期间，设备端会通过向客户端定期发送握手报文的方法，对用户的在线情况进行监测。缺省情况下，两次握手请求报文都得不到客户端应答，设备端就会让用户下线，防止用户因为异常原因下线而设备无法感知。 客户端也可以发送EAPOL-Logoff报文给设备端，主动要求下线。设备端把端口状态从授权状态改变成未授权状态，并向客户端发送EAP-Failure报文。 关于WiFidog：Portal认证，通常也会叫Web认证，未认证用户上网时，设备强制用户登录到特定站点，用户可以免费访问其中的服务。当用户需要使用互联网中的其它信息时，必须在门户网站进行认证，只有认证通过后才可以使用互联网资源。现金很多中国移动CMCC、中国联通、中国电信ChinaNet的WIFI都使用这种认证接入方式。 在OpenWRT上实现Portal认证，实际上早已有解决方案： chillispot，但原维护作者停止更新，被chillispot.info接管继续开发； coova-chilli，它是基于chillispot开发拓展的，功能最为强大；可以去官方看一下Coova-chilli； wifidog，前两个由于原维护作者停止更新，笔者也没有深入研究，重点钻研了wifidog，Wifidog也是OpenWRT和DD-WRT中实现Portal比较出名的。但是，Wifidog只是实现AP认证网关，需要配合外部的Portal服务器才能使用，Portal主要是提供认证所需的WEB页面且实现认证计费等的功能。虽然这也有很多商用解决方案，例如wiwiz、wifiap等，但是这些商业解决方案的目标都是盈利，即使可以免费使用，免费账号的功能和权限都受到了很大的限制，例如不能自定义页面，Web认证页面有广告等等。有条件的人可能打算自己搭建Portal服务器，但是看看Wifidog的官方Wiki，对搭建过程实在是难以理解。后来，笔者发现网络上还有一个 authpuppy方案 ，官方网站 www.authpuppy.org ，是一个已实现好的Wifidog认证服务器，里面包含各种插件供你使用，官方的安装过程也很简单，如果你懂的HTML和面向对象编程的相关知识且拥有一个服务器，可以自行修改认证页面，使用authpuppy也是一个不错的方案。 如何 自行编写一个轻量级的Web Portal认证服务器 ： Wifidog的工作原理： 客户端发出初始化请求，比如访问 www.dqrun.com 。 网关的防火墙规则将这个请求重定向到本地网关的端口上。这个端口是Wifidog监听的端口。 Wfidog提供一个HTTP重定向回复，重定向到Web认证页面，重定向的Url的Querystring中包含了Gateway的ID，Gateway的FQDN以及其他的信息。 用户向认证服务器发出认证请求 1234gw_id=[GatewayID, default: “default”]gw_address=[GatewayAddress, internal IP of router]gw_port=[GatewayPort, port that wifidog Gateway is listening on]url=[user requested url]； 网关返回一个（可以是自定义的）splash（也称作“登录”）页面。 用户提供他的凭据信息，比如用户名和密码。 成功认证的话，客户端将会被重定向到网关的自己的web页面上，并且带有一个认证凭据（一个一次性的token），内容比如：http://GatewayIP:GatewayPort/wifidog/auth?token=[auth token]； 用户就是用获取到的凭据访问网关。 网关去认证服务器询问token的有效性。 认证服务器确认token的有效性。 网关发送重定向给客户端，以从认证服务器上获取 成功提示页面，重定向到 http://portal_server:port/portal_script 这个位置。 认证服务器通知客户请求成功，可以上网了。 待完成工作：装wifidog ，配置:1）监听端口 2)服务器地址 3）5个脚本的地址(login, portal, msg, ping, auth) 配置方法：远程登陆openwrt: ssh root@192.168.1.1， 然后修改/etc/wifidog.conf文件。 将笔记本搭建成服务器 添加对LED的频率提取功能 实现动态调节LED频率,将此功能添加至系统 2019/07/08 路由器刷openwrt系统恢复出厂：断电后，先按住reset再通电。登陆192.168.1.1（breed web），先点“恢复出厂”，选择“openwrt”；再点击“更新固件”，选中已下载好的openwrt镜像，进行固件更新。 解决路由器联网问题 设置密码：点击Go to password configuration...，敲入2遍新的路由器密码，点击页面最下面的 保存执行按钮，密码修改即时生效。 设置主机名和时区：System菜单的system进去，主机名改为自己希望的名称，时区设置为Asia/Shanghai，保存。 联网设置 :点击菜单Network中的第二项，可以选择2G或5G无线网络连接WIFI，按 scan扫描按钮，稍等出现列表中，选择自己(想通过这个路由连接)的WIFI，输入密码，按提交，然后稍等，按保存执行。 ubuntu16.04编译OpenWrt环境搭建： ubuntu下OpenWrt编译环境需要安装很多组件：sudo apt-get install gccsudo apt-get install g++sudo apt-get install binutilssudo apt-get install patchsudo apt-get install bzip2sudo apt-get install flexsudo apt-get install bisonsudo apt-get install makesudo apt-get install autoconfsudo apt-get install gettextsudo apt-get install texinfosudo apt-get install unzipsudo apt-get install sharutilssudo apt-get install subversionsudo apt-get install libncurses5-devsudo apt-get install ncurses-termsudo apt-get install zlib1g-devsudo apt-get install subversionsudo apt-get install git-coresudo apt-get install gawksudo apt-get install asciidocsudo apt-get install libz-dev当然安装之前最好先更新下组件包：sudo apt-get update逐个安装… 新建一个openwrt目录，使用命令：mkdir openwrtsudo chmod 777 openwrt接下来的所有命令都在/openwrt目录下运行 下载OpenWrt源码:git clone git://git.openwrt.org/openwrt/openwrt.git 添加软件扩展包：cd /home/ngmi/openwrt/openwrt/cp feeds.conf.default feeds.conf(将feeds.conf.default修改为feeds.conf) 更新扩展，安装扩展：./scripts/feeds update -a./scripts/feeds install -a 测试下编译环境，使用命令：make defconfig make menuconfig如果一切正常，会出现一个配置菜单，可以选择要编译的固件平台、型号，还能选择固件中要添加的功能和组件，至此编译环境就搭建好了。 在OpenWrt的路由器上安装Wifidog应用程序 在OpenWrt系统的源码文件下，编辑feeds.conf.default文件vim feeds.conf.default在其中增加一行：src-git wifidog https://github.com/wifidog/wifidog-gateway.git 然后更新，再安装：./scripts/feeds update -a./scripts/feeds install -a 终端执行编译命令make menuconfig 在Network/captive portals/下选择wifidog 就有选择 WiFiDog 这一项了 2019/07/09 配置服务器中遇到的问题问题： python3 manage.py runserver 0.0.0.0:8000123456789101112131415161718Traceback (most recent call last): File &quot;manage.py&quot;, line 22, in &lt;module&gt; execute_from_command_line(sys.argv) File &quot;/usr/local/lib/python3.5/dist-packages/django/core/management/__init__.py&quot;, line 381, in execute_from_command_line utility.execute() File &quot;/usr/local/lib/python3.5/dist-packages/django/core/management/__init__.py&quot;, line 375, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File &quot;/usr/local/lib/python3.5/dist-packages/django/core/management/base.py&quot;, line 323, in run_from_argv self.execute(*args, **cmd_options) File &quot;/usr/local/lib/python3.5/dist-packages/django/core/management/commands/runserver.py&quot;, line 60, in execute super().execute(*args, **options) File &quot;/usr/local/lib/python3.5/dist-packages/django/core/management/base.py&quot;, line 364, in execute output = self.handle(*args, **options) File &quot;/home/ngmi/lightFreq-master/my_wifi_auth_server/django_pdb/management/commands/runserver.py&quot;, line 59, in handle and middleware not in settings.MIDDLEWARE_CLASSES): File &quot;/usr/local/lib/python3.5/dist-packages/django/conf/__init__.py&quot;, line 80, in __getattr__ val = getattr(self._wrapped, name)AttributeError: &apos;Settings&apos; object has no attribute &apos;MIDDLEWARE_CLASSES&apos; 解决方法： 1234middleware = 'django_pdb.middleware.PdbMiddleware' if ((pdb_option or settings.DEBUG) and middleware not in settings.MIDDLEWARE): settings.MIDDLEWARE += (middleware,) 由于Django版本的问题，需要将（lightFreq-master/my_wifi_auth_server/django_pdb/management/conmands/runserver.py）以上代码中原本的MIDDLEWARE_CLASSES改为MIDDLEWARE。 问题： HTTP_HOST header: '0.0.0.0:8000'. You may need to add '0.0.0.0' to ALLOWED_HOSTS.12Bad Request: /[09/Jul/2019 14:14:40] &quot;GET / HTTP/1.1&quot; 400 66219 进入http://0.0.0.0:8000页面显示Invalid…解决办法：将lightFreq-master/my_wifi_auth_server/Auth_server/settings.py文件中ALLOWED_HOSTS = [&#39;192.168.1.162&#39;,&#39;127.0.0.1&#39;]修改为ALLOWED_HOSTS = [&#39;*&#39;]","categories":[{"name":"Light Frequency Authenticate","slug":"Light-Frequency-Authenticate","permalink":"http://yoursite.com/categories/Light-Frequency-Authenticate/"}],"tags":[{"name":"lightFre","slug":"lightFre","permalink":"http://yoursite.com/tags/lightFre/"}]},{"title":"为Hexo的Next主题添加计数功能","slug":"为Hexo的Next主题添加计数功能","date":"2019-07-03T10:22:33.000Z","updated":"2020-07-07T04:05:48.954Z","comments":true,"path":"2019/07/03/为Hexo的Next主题添加计数功能/","link":"","permalink":"http://yoursite.com/2019/07/03/为Hexo的Next主题添加计数功能/","excerpt":"blog中添加wordcount功能","text":"blog中添加wordcount功能 1.在根目录git bash： npm install hexo-wordcount --save 2.在主题配置文件(hexo\\themes\\next\\config.yml)中打开wordcount功能 # Post wordcount display settings # Dependencies: https://github.com/willin/hexo-wordcount post_wordcount: item_text: true wordcount: true min2read: true totalcount: true separated_meta: true3.修改 hexo\\themes\\next\\layout\\post.swig，将下面代码复制到文件中： &lt;span title=&quot;{{ __('post.wordcount') }}&quot;&gt; {{ wordcount(post.content) }} 字 &lt;/span&gt; &lt;span title=&quot;{{ __('post.min2read') }}&quot;&gt; {{ min2read(post.content) }} 分钟 &lt;/span&gt;","categories":[{"name":"Blogthings","slug":"Blogthings","permalink":"http://yoursite.com/categories/Blogthings/"}],"tags":[{"name":"hexo next","slug":"hexo-next","permalink":"http://yoursite.com/tags/hexo-next/"}]}]}